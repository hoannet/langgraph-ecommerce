# Intent Classification Errors - Troubleshooting Guide

## âŒ Lá»—i Phá»• Biáº¿n: Misclassification

### VÃ­ Dá»¥ Tá»« Logs

```
User Message: "Báº¡n khoáº» khÃ´ng?" (How are you?)
Expected Intent: general
Actual Intent: payment âœ—
Confidence: 0.95
Reasoning: "The message explicitly asks about payment" â† HALLUCINATION!
```

---

## ðŸ” NguyÃªn NhÃ¢n

### 1. **Small Language Model Limitations**

Model hiá»‡n táº¡i: `google/gemma-3-1b` (1 billion parameters)

**Váº¥n Ä‘á»**:
- âŒ **Limited understanding** - Model nhá» khÃ³ hiá»ƒu context phá»©c táº¡p
- âŒ **Hallucination** - Táº¡o ra reasoning khÃ´ng Ä‘Ãºng sá»± tháº­t
- âŒ **Overconfidence** - Confidence cao (0.95) dÃ¹ classify sai
- âŒ **Language confusion** - KhÃ³ vá»›i tiáº¿ng Viá»‡t vÃ  mixed languages

### 2. **Prompt KhÃ´ng Äá»§ RÃµ RÃ ng**

**TrÆ°á»›c khi fix**:
```
Intent categories:
- PAYMENT: User wants to make a payment...
- GENERAL: General conversation, greetings...
```

**Váº¥n Ä‘á»**: KhÃ´ng cÃ³ examples cá»¥ thá»ƒ â†’ model dá»… nháº§m láº«n

---

## âœ… Giáº£i PhÃ¡p

### **Solution 1: Cáº£i Thiá»‡n Prompt** â­ (IMPLEMENTED)

**ÄÃ£ fix trong**: [`src/prompts/system_prompts.py`](file:///projects/agentic-ai/langgraph-test/src/prompts/system_prompts.py)

**Thay Ä‘á»•i**:
1. âœ… ThÃªm **concrete examples** cho má»—i intent
2. âœ… ThÃªm **IMPORTANT RULES** section
3. âœ… Explicit instruction: "Only classify as PAYMENT if explicitly mentions payment"
4. âœ… Include Vietnamese examples: "Báº¡n khoáº» khÃ´ng?" â†’ GENERAL

**New Prompt**:
```python
Intent categories with examples:

1. PAYMENT - User wants to make a payment...
   Examples:
   - "I want to make a payment of $100"
   - "TÃ´i muá»‘n thanh toÃ¡n 50000 VNÄ"
   
3. GENERAL - General conversation, greetings...
   Examples:
   - "Hello, how are you?"
   - "Báº¡n khoáº» khÃ´ng?"  â† Explicit example!

IMPORTANT RULES:
- Only classify as PAYMENT if explicitly mentions payment
- Greetings should be GENERAL, not PAYMENT
- Be conservative - when in doubt, choose GENERAL
```

**Expected Improvement**: 60-80% better accuracy

---

### **Solution 2: Use Larger Model** ðŸš€ (RECOMMENDED)

**Current**: `google/gemma-3-1b` (1B params)

**Better Options**:

#### Option A: Gemma 2 (7B-9B)
```bash
# In LM Studio, load:
- google/gemma-2-9b-it
- google/gemma-2-7b-it
```

**Pros**:
- âœ… Much better understanding
- âœ… Less hallucination
- âœ… Better multilingual support

**Cons**:
- âš ï¸ Requires more RAM (8-16GB)
- âš ï¸ Slower inference

#### Option B: Llama 3.1 (8B)
```bash
# In LM Studio, load:
- meta-llama/Llama-3.1-8B-Instruct
```

**Pros**:
- âœ… Excellent instruction following
- âœ… Very good at classification tasks
- âœ… Strong reasoning

#### Option C: Qwen 2.5 (7B)
```bash
# In LM Studio, load:
- Qwen/Qwen2.5-7B-Instruct
```

**Pros**:
- âœ… Great multilingual (English + Vietnamese)
- âœ… Fast inference
- âœ… Good at structured output

**CÃ¡ch Ä‘á»•i model**:
```bash
# 1. Load model má»›i trong LM Studio
# 2. Update .env
LM_STUDIO_MODEL_NAME=Qwen/Qwen2.5-7B-Instruct

# 3. Restart server (auto-reload sáº½ pick up changes)
```

---

### **Solution 3: Add Fallback Logic** ðŸ›¡ï¸

ThÃªm validation layer Ä‘á»ƒ catch obvious mistakes:

```python
# src/agents/intent_classifier.py

def _validate_classification(
    self, 
    message: str, 
    intent: IntentType, 
    confidence: float
) -> tuple[IntentType, float]:
    """Validate and correct obvious misclassifications."""
    
    # Greetings should be GENERAL
    greetings = [
        "hello", "hi", "hey", "good morning", "good afternoon",
        "xin chÃ o", "chÃ o", "báº¡n khoáº» khÃ´ng", "how are you"
    ]
    
    message_lower = message.lower()
    
    # If classified as PAYMENT but is a greeting
    if intent == IntentType.PAYMENT:
        for greeting in greetings:
            if greeting in message_lower:
                logger.warning(
                    f"Correcting misclassification: '{message}' "
                    f"from PAYMENT to GENERAL (greeting detected)"
                )
                return IntentType.GENERAL, 0.6
    
    # If PAYMENT but no payment keywords
    payment_keywords = [
        "payment", "pay", "transaction", "thanh toÃ¡n", 
        "Ä‘Æ¡n", "invoice", "bill", "charge"
    ]
    
    if intent == IntentType.PAYMENT:
        has_payment_keyword = any(
            keyword in message_lower 
            for keyword in payment_keywords
        )
        if not has_payment_keyword:
            logger.warning(
                f"Correcting misclassification: '{message}' "
                f"from PAYMENT to GENERAL (no payment keywords)"
            )
            return IntentType.GENERAL, 0.5
    
    return intent, confidence
```

**Usage**:
```python
async def classify(self, messages, context):
    # ... existing code ...
    result_dict = json.loads(cleaned_json)
    
    # Validate classification
    intent, confidence = self._validate_classification(
        messages[-1].content,
        IntentType(result_dict["intent"]),
        result_dict["confidence"]
    )
    
    return IntentClassification(
        intent=intent,
        confidence=confidence,
        reasoning=result_dict.get("reasoning")
    )
```

---

### **Solution 4: Few-Shot Examples in Prompt**

ThÃªm examples trá»±c tiáº¿p vÃ o prompt:

```python
# src/prompts/agent_prompts.py

INTENT_CLASSIFICATION_PROMPT = ChatPromptTemplate.from_messages([
    ("system", "{system_prompt}"),
    # Add few-shot examples
    ("human", "I want to make a payment of $100"),
    ("assistant", '{"intent": "payment", "confidence": 0.95, "reasoning": "Explicit payment request"}'),
    ("human", "Báº¡n khoáº» khÃ´ng?"),
    ("assistant", '{"intent": "general", "confidence": 0.95, "reasoning": "Greeting in Vietnamese"}'),
    ("human", "What are your business hours?"),
    ("assistant", '{"intent": "faq", "confidence": 0.90, "reasoning": "Question about service"}'),
    # Actual user message
    MessagesPlaceholder(variable_name="chat_history", optional=True),
    ("human", "Analyze this: {user_message}"),
])
```

---

## ðŸ“Š Testing After Fixes

### Test Cases

```bash
# 1. Greeting (should be GENERAL)
curl -X POST "http://localhost:8000/chat/" \
  -H "Content-Type: application/json" \
  -d '{"message": "Báº¡n khoáº» khÃ´ng?"}'

# Expected: intent="general"

# 2. Payment (should be PAYMENT)
curl -X POST "http://localhost:8000/chat/" \
  -H "Content-Type: application/json" \
  -d '{"message": "TÃ´i muá»‘n thanh toÃ¡n 100 USD"}'

# Expected: intent="payment"

# 3. FAQ (should be FAQ)
curl -X POST "http://localhost:8000/chat/" \
  -H "Content-Type: application/json" \
  -d '{"message": "What are your business hours?"}'

# Expected: intent="faq"

# 4. Ambiguous (should be GENERAL with lower confidence)
curl -X POST "http://localhost:8000/chat/" \
  -H "Content-Type: application/json" \
  -d '{"message": "Tell me more"}'

# Expected: intent="general", confidence < 0.7
```

### Monitor Logs

```bash
# Watch classification results
tail -f data/logs/chatbot.log | grep "Intent classification result"

# Check for corrections
tail -f data/logs/chatbot.log | grep "Correcting misclassification"
```

---

## ðŸŽ¯ Recommended Action Plan

### Immediate (Now)
1. âœ… **Improved prompt** (already done)
2. ðŸ”„ **Test with current model** - see if prompt helps
3. ðŸ“Š **Monitor accuracy** - check logs

### Short-term (Today/Tomorrow)
1. ðŸš€ **Upgrade to 7B model** (Qwen 2.5 or Gemma 2)
   - Better accuracy
   - Still reasonable speed
2. ðŸ›¡ï¸ **Add fallback validation** (Solution 3)
   - Catch obvious mistakes
   - Log corrections for analysis

### Long-term (Production)
1. ðŸ“ˆ **Collect misclassification data**
2. ðŸŽ“ **Fine-tune model** on your specific use cases
3. ðŸ” **Add confidence thresholds**
   - If confidence < 0.7 â†’ ask user to clarify
4. ðŸ“Š **A/B testing** different models and prompts

---

## ðŸ”§ Quick Fix Commands

```bash
# 1. Test current fix (improved prompt)
curl -X POST "http://localhost:8000/chat/" \
  -H "Content-Type: application/json" \
  -d '{"message": "Báº¡n khoáº» khÃ´ng?"}'

# 2. Change to better model in LM Studio
# Load: Qwen/Qwen2.5-7B-Instruct

# 3. Update .env
echo "LM_STUDIO_MODEL_NAME=Qwen/Qwen2.5-7B-Instruct" >> .env

# 4. Server auto-reloads, test again
curl -X POST "http://localhost:8000/chat/" \
  -H "Content-Type: application/json" \
  -d '{"message": "Báº¡n khoáº» khÃ´ng?"}'
```

---

## ðŸ“ˆ Expected Results

### With Improved Prompt (Current)
- Accuracy: 70-80% (up from ~50%)
- Still some errors with small model

### With 7B Model + Improved Prompt
- Accuracy: 90-95%
- Rare misclassifications
- Better confidence calibration

### With Fallback Validation
- Accuracy: 95-98%
- Catches most obvious mistakes
- More robust system

---

## ðŸ’¡ Key Takeaways

1. **Small models struggle** - 1B params not enough for reliable classification
2. **Prompts matter** - Good examples and rules help significantly
3. **Validation helps** - Rule-based fallback catches obvious errors
4. **Model size vs speed** - Trade-off between accuracy and latency
5. **Monitor and iterate** - Collect data, improve over time
